{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5j_dr-gd8jJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reads a CSV file named iris data andnstores in Pandas DataFrame \n",
        "data = pd.read_csv('iris.csv', header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'])\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVa59ZvWqAVT",
        "outputId": "8587d722-07ff-4be6-94ac-990db6cb05b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width      class\n",
            "0             5.1          3.5           1.4          0.2     Setosa\n",
            "1             4.9          3.0           1.4          0.2     Setosa\n",
            "2             4.7          3.2           1.3          0.2     Setosa\n",
            "3             4.6          3.1           1.5          0.2     Setosa\n",
            "4             5.0          3.6           1.4          0.2     Setosa\n",
            "..            ...          ...           ...          ...        ...\n",
            "145           6.7          3.0           5.2          2.3  Virginica\n",
            "146           6.3          2.5           5.0          1.9  Virginica\n",
            "147           6.5          3.0           5.2          2.0  Virginica\n",
            "148           6.2          3.4           5.4          2.3  Virginica\n",
            "149           5.9          3.0           5.1          1.8  Virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generates a randomized array of integers from 0 to the number of rows \n",
        "indices = np.random.permutation(data.shape[0])\n",
        "\n",
        "# calculating the index on which data will be divided \n",
        "div = int(0.75 * len(indices))\n",
        "\n",
        "# dividing the indexes into two array\n",
        "development_id, test_id = indices[:div], indices[div:]\n",
        "\n",
        "# using loc method of pandas dataframe which will select a particular row and its all columns\n",
        "# its just like splitting into training set and testing set\n",
        "\n",
        "development_set, test_set = data.loc[development_id,:], data.loc[test_id,:]\n",
        "print(\"Development Set:\\n\", development_set, \"\\n\\nTest Set:\\n\", test_set)"
      ],
      "metadata": {
        "id": "ceAO-AwNq1vK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3be5dc-419e-4e6c-bff7-0b6013ea677b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Development Set:\n",
            "      sepal_length  sepal_width  petal_length  petal_width      class\n",
            "7             5.0          3.4           1.5          0.2     Setosa\n",
            "41            4.5          2.3           1.3          0.3     Setosa\n",
            "6             4.6          3.4           1.4          0.3     Setosa\n",
            "1             4.9          3.0           1.4          0.2     Setosa\n",
            "111           6.4          2.7           5.3          1.9  Virginica\n",
            "..            ...          ...           ...          ...        ...\n",
            "13            4.3          3.0           1.1          0.1     Setosa\n",
            "26            5.0          3.4           1.6          0.4     Setosa\n",
            "3             4.6          3.1           1.5          0.2     Setosa\n",
            "35            5.0          3.2           1.2          0.2     Setosa\n",
            "137           6.4          3.1           5.5          1.8  Virginica\n",
            "\n",
            "[112 rows x 5 columns] \n",
            "\n",
            "Test Set:\n",
            "      sepal_length  sepal_width  petal_length  petal_width       class\n",
            "5             5.4          3.9           1.7          0.4      Setosa\n",
            "66            5.6          3.0           4.5          1.5  Versicolor\n",
            "141           6.9          3.1           5.1          2.3   Virginica\n",
            "78            6.0          2.9           4.5          1.5  Versicolor\n",
            "43            5.0          3.5           1.6          0.6      Setosa\n",
            "96            5.7          2.9           4.2          1.3  Versicolor\n",
            "87            6.3          2.3           4.4          1.3  Versicolor\n",
            "104           6.5          3.0           5.8          2.2   Virginica\n",
            "49            5.0          3.3           1.4          0.2      Setosa\n",
            "122           7.7          2.8           6.7          2.0   Virginica\n",
            "12            4.8          3.0           1.4          0.1      Setosa\n",
            "102           7.1          3.0           5.9          2.1   Virginica\n",
            "17            5.1          3.5           1.4          0.3      Setosa\n",
            "92            5.8          2.6           4.0          1.2  Versicolor\n",
            "121           5.6          2.8           4.9          2.0   Virginica\n",
            "68            6.2          2.2           4.5          1.5  Versicolor\n",
            "132           6.4          2.8           5.6          2.2   Virginica\n",
            "2             4.7          3.2           1.3          0.2      Setosa\n",
            "42            4.4          3.2           1.3          0.2      Setosa\n",
            "48            5.3          3.7           1.5          0.2      Setosa\n",
            "81            5.5          2.4           3.7          1.0  Versicolor\n",
            "146           6.3          2.5           5.0          1.9   Virginica\n",
            "24            4.8          3.4           1.9          0.2      Setosa\n",
            "98            5.1          2.5           3.0          1.1  Versicolor\n",
            "120           6.9          3.2           5.7          2.3   Virginica\n",
            "89            5.5          2.5           4.0          1.3  Versicolor\n",
            "142           5.8          2.7           5.1          1.9   Virginica\n",
            "147           6.5          3.0           5.2          2.0   Virginica\n",
            "112           6.8          3.0           5.5          2.1   Virginica\n",
            "11            4.8          3.4           1.6          0.2      Setosa\n",
            "32            5.2          4.1           1.5          0.1      Setosa\n",
            "46            5.1          3.8           1.6          0.2      Setosa\n",
            "100           6.3          3.3           6.0          2.5   Virginica\n",
            "143           6.8          3.2           5.9          2.3   Virginica\n",
            "52            6.9          3.1           4.9          1.5  Versicolor\n",
            "69            5.6          2.5           3.9          1.1  Versicolor\n",
            "139           6.9          3.1           5.4          2.1   Virginica\n",
            "129           7.2          3.0           5.8          1.6   Virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the class labels for development and testing data\n",
        "test_class = list(test_set.iloc[:,-1])\n",
        "dev_class = list(development_set.iloc[:,-1])\n",
        "\n",
        "# calculating mean and standard deviation for both development set and testing set\n",
        "mean_development_set = development_set.mean()\n",
        "mean_test_set = test_set.mean()\n",
        "std_development_set = development_set.std()\n",
        "std_test_set = test_set.std()"
      ],
      "metadata": {
        "id": "d8X1jbuatel1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2b7c50-6ec6-4be1-af46-84e381f51a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-f2c127012c5f>:6: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  mean_development_set = development_set.mean()\n",
            "<ipython-input-7-f2c127012c5f>:7: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  mean_test_set = test_set.mean()\n",
            "<ipython-input-7-f2c127012c5f>:8: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  std_development_set = development_set.std()\n",
            "<ipython-input-7-f2c127012c5f>:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  std_test_set = test_set.std()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding Euclidean Distance\n",
        "def euclideanDistance(data_1, data_2, data_len):\n",
        "    dist = 0\n",
        "    for i in range(data_len):\n",
        "        dist = dist + np.square(data_1[i] - data_2[i])\n",
        "    return np.sqrt(dist)\n",
        "\n",
        "# Formula for Normalized Euclidean Distance\n",
        "# d(p, q) = sqrt(sum(((pi - mu_i) / sigma_i - (qi - mu_i) / sigma_i) ** 2))\n",
        "# pi and qi are features of data_1 and data_2 and mu is mean and sigma_i is standard deviation\n",
        "def normalizedEuclideanDistance(data_1, data_2, data_len, data_mean, data_std):\n",
        "    n_dist = 0\n",
        "    for i in range(data_len):\n",
        "        n_dist = n_dist + (np.square(((data_1[i] - data_mean[i])/data_std[i]) - ((data_2[i] - data_mean[i])/data_std[i])))\n",
        "    return np.sqrt(n_dist)\n",
        "\n",
        "\n",
        "def cosineSimilarity(data_1, data_2):\n",
        "# computes the dot product of data_1 and data_2 without considering the last element of data_2.\n",
        "    dot = np.dot(data_1, data_2[:-1])\n",
        "    norm_data_1 = np.linalg.norm(data_1)\n",
        "    norm_data_2 = np.linalg.norm(data_2[:-1])\n",
        "\n",
        "# It computes the cosine similarity between data_1 and data_2, dividing dot by the product of the two Euclidean norms.\n",
        "    cos = dot / (norm_data_1 * norm_data_2)\n",
        "    return (1-cos)\n",
        "\n",
        "# This function calculates the distance between the test instance and all instances\n",
        "# Then it finds the k nearest neighbors and returns the class\n",
        "\n",
        "# For K-nearest neighbours \n",
        "def knn(dataset, testInstance, k, dist_method, dataset_mean, dataset_std): \n",
        "    distances = {}\n",
        "\n",
        "    length = testInstance.shape[1]\n",
        "    if dist_method == 'euclidean':\n",
        "        for x in range(len(dataset)):\n",
        "            dist_up = euclideanDistance(testInstance, dataset.iloc[x], length)\n",
        "            distances[x] = dist_up[0]\n",
        "    elif dist_method == 'normalized_euclidean':\n",
        "        for x in range(len(dataset)):\n",
        "            dist_up = normalizedEuclideanDistance(testInstance, dataset.iloc[x], length, dataset_mean, dataset_std)\n",
        "            distances[x] = dist_up[0]\n",
        "    elif dist_method == 'cosine':\n",
        "        for x in range(len(dataset)):\n",
        "            dist_up = cosineSimilarity(testInstance, dataset.iloc[x])\n",
        "            distances[x] = dist_up[0]\n",
        "\n",
        "    # Sort values based on distance\n",
        "    sort_distances = sorted(distances.items(), key=operator.itemgetter(1))\n",
        "    neighbors = []\n",
        "    # Extracting nearest k neighbors\n",
        "    for x in range(k):\n",
        "        neighbors.append(sort_distances[x][0])\n",
        "    # Initializing counts for 'class' labels counts as 0\n",
        "    counts = {\"Iris-setosa\" : 0, \"Iris-versicolor\" : 0, \"Iris-virginica\" : 0}\n",
        "    # Computing the most frequent class\n",
        "    for x in range(len(neighbors)):\n",
        "        response = dataset.iloc[neighbors[x]][-1] \n",
        "        if response in counts:\n",
        "            counts[response] += 1\n",
        "        else:\n",
        "            counts[response] = 1\n",
        "    # Sorting the class in reverse order to get the most frequest class\n",
        "    sort_counts = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    return(sort_counts[0][0])\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "3EmMkdo2uXlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we implememt KNN algorithm on development set for various values of K\n",
        "# It iterates through each data point in the development set \n",
        "# to determine its predicted class label based on the k nearest neighbors\n",
        "\n",
        "row_list = []\n",
        "for index, rows in development_set.iterrows():\n",
        "    my_list =[rows.sepal_length, rows.sepal_width, rows.petal_length, rows.petal_width]       \n",
        "    row_list.append([my_list])\n",
        "# k values for the number of neighbors that need to be considered\n",
        "k_n = [1, 3, 5, 7]\n",
        "# Distance metrics\n",
        "distance_methods = ['euclidean', 'normalized_euclidean', 'cosine']\n",
        "# Performing kNN on the development set by iterating all of the development set data points and for each k and each distance metric\n",
        "obs_k = {}\n",
        "for dist_method in distance_methods:\n",
        "    development_set_obs_k = {}\n",
        "    for k in k_n:\n",
        "        development_set_obs = []\n",
        "        for i in range(len(row_list)):\n",
        "          development_set_obs.append(knn(development_set, pd.DataFrame(row_list[i]), k, dist_method, mean_development_set, std_development_set))\n",
        "        development_set_obs_k[k] = development_set_obs\n",
        "    # Nested Dictionary containing the observed class for each k and each distance metric (obs_k of the form obs_k[dist_method][k])\n",
        "    obs_k[dist_method] = development_set_obs_k\n",
        "    print(dist_method.upper() + \" distance method performed on the dataset for all k values!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "sftWmxPYuXg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5bae783-dc07-4287-b65a-966f584d1b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EUCLIDEAN distance method performed on the dataset for all k values!\n",
            "NORMALIZED_EUCLIDEAN distance method performed on the dataset for all k values!\n",
            "COSINE distance method performed on the dataset for all k values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = {}\n",
        "for key in obs_k.keys():\n",
        "    accuracy[key] = {}\n",
        "    for k_value in obs_k[key].keys():\n",
        "        #print('k = ', key)\n",
        "        count = 0\n",
        "        for i,j in zip(dev_class, obs_k[key][k_value]):\n",
        "            if i == j:\n",
        "                count = count + 1\n",
        "            else:\n",
        "                pass\n",
        "        accuracy[key][k_value] = count/(len(dev_class))\n",
        "\n",
        "# Storing the accuracy for each k and each distance metric into a dataframe\n",
        "df_res = pd.DataFrame({'k': k_n})\n",
        "for key in accuracy.keys():\n",
        "    value = list(accuracy[key].values())\n",
        "    df_res[key] = value\n",
        "print(df_res)\n",
        "\n",
        "# Plotting a Bar Chart for accuracy\n",
        "draw = df_res.plot(x='k', y=['euclidean', 'normalized_euclidean', 'cosine'], kind=\"bar\", colormap='YlGnBu')\n",
        "draw.set(ylabel='Accuracy')\n",
        "\n",
        "# Ignoring k=1 if the value of accuracy for k=1 is 100%, since this mostly implies overfitting\n",
        "df_res.loc[df_res['k'] == 1.0, ['euclidean', 'normalized_euclidean', 'cosine']] = np.nan\n",
        "\n",
        "# Fetching the best k value for using all hyper-parameters\n",
        "# In case the accuracy is the same for different k and different distance metric selecting the first of all the same\n",
        "column_val = [c for c in df_res.columns if not c.startswith('k')]\n",
        "col_max = df_res[column_val].max().idxmax()\n",
        "best_dist_method = col_max\n",
        "row_max = df_res[col_max].argmax()\n",
        "best_k = int(df_res.iloc[row_max]['k'])\n",
        "if df_res.isnull().values.any():\n",
        "    print('\\n\\n\\nBest k value is\\033[1m', best_k, '\\033[0mand best distance metric is\\033[1m', best_dist_method, '\\033[0m. Ignoring k=1 if the value of accuracy for k=1 is 100%, since this mostly implies overfitting')\n",
        "else:\n",
        "    print('\\n\\n\\nBest k value is\\033[1m', best_k, '\\033[0mand best distance metric is\\033[1m', best_dist_method, '\\033[0m.')"
      ],
      "metadata": {
        "id": "PXbueqHU5kTe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "5dd5436b-231a-4ea8-a7b9-5bf54eb81881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   k  euclidean  normalized_euclidean    cosine\n",
            "0  1   1.000000              1.000000  1.000000\n",
            "1  3   0.946429              0.937500  0.973214\n",
            "2  5   0.964286              0.937500  0.955357\n",
            "3  7   0.964286              0.955357  0.964286\n",
            "\n",
            "\n",
            "\n",
            "Best k value is\u001b[1m 3 \u001b[0mand best distance metric is\u001b[1m cosine \u001b[0m. Ignoring k=1 if the value of accuracy for k=1 is 100%, since this mostly implies overfitting\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n\\n\\nBest k value is\\033[1m', best_k, '\\033[0mand best distance metric is\\033[1m', best_dist_method, '\\033[0m')"
      ],
      "metadata": {
        "id": "DNWXmpPf5qEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d818c05-633f-4997-9a23-d74c6aaea7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Best k value is\u001b[1m 3 \u001b[0mand best distance metric is\u001b[1m cosine \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of list of all columns except 'class' by iterating through the development set\n",
        "row_list_test = []\n",
        "for index, rows in test_set.iterrows(): \n",
        "    my_list =[rows.sepal_length, rows.sepal_width, rows.petal_length, rows.petal_width]       \n",
        "    row_list_test.append([my_list])\n",
        "test_set_obs = []\n",
        "for i in range(len(row_list_test)):\n",
        "    test_set_obs.append(knn(test_set, pd.DataFrame(row_list_test[i]), best_k, best_dist_method, mean_test_set, std_test_set))\n",
        "#print(test_set_obs)\n",
        "\n",
        "count = 0\n",
        "for i,j in zip(test_class, test_set_obs):\n",
        "    if i == j:\n",
        "        count = count + 1\n",
        "    else:\n",
        "        pass\n",
        "accuracy_test = count/(len(test_class))\n",
        "print('Final Accuracy of the Test dataset is ', accuracy_test)"
      ],
      "metadata": {
        "id": "c4NZeDft5tQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46352fd0-59b6-4b37-f2af-f8017dc9e64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy of the Test dataset is  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! jupyter nbconvert --to html KNN+ConfusionMatrix+Iris_Data_set+Colab-.ipynb"
      ],
      "metadata": {
        "id": "L5-v3ZPFUWjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7dcbda-f1fb-4a29-d1b1-f0962324e583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern 'KNN+ConfusionMatrix+Iris_Data_set+Colab-.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only \n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place, \n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document. \n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            `Exporter` class\n",
            "    Default: 'html'\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the \n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    overwrite base name use for output files.\n",
            "                can only be used when converting one notebook at a time.\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current \n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy \n",
            "            of reveal.js. \n",
            "            For speaker notes to work, this must be a relative path to a local \n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb\n",
            "\n",
            "            which will convert mynotebook.ipynb to the default format (probably HTML).\n",
            "\n",
            "            You can specify the export format with `--to`.\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
            "            can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template basic mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of \n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}